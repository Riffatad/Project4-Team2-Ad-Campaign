{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c0a29f-3e6f-4eae-b331-bc12a9539d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee112c-3cc5-4e4f-8e3d-58410af9bf3d",
   "metadata": {},
   "source": [
    "# Fetch Data from SQLite Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad476f44-15d9-41b5-8824-bb891857ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function loads ad campaign data from an SQLite database.\n",
    "#If an error occurs (e.g., table not found), it prints an error message.\n",
    "#It ensures the connection is closed even if an error happens\n",
    "\n",
    "def fetch_data():\n",
    "    \"\"\"Retrieve data from the SQLite database.\"\"\"\n",
    "    conn = sqlite3.connect(\"ad_campaigns.db\")\n",
    "    try:\n",
    "        df = pd.read_sql(\"SELECT * FROM ad_campaigns\", conn)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329cc916-9f73-43dc-83f7-e613d151d4f8",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206b2a72-ddc3-4cbc-a31e-6b02fb1732f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess Data\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Cleans and preprocesses ad campaign data.\"\"\"\n",
    "    #Step 1: Handle Empty DataFrames\n",
    "    if df is None or df.empty:\n",
    "        print(\" Error: DataFrame is empty!\")\n",
    "        return None  \n",
    "        \n",
    "# Step 2: Remove Missing Values\n",
    "# Drops any rows with missing values (NaN).\n",
    "# Creates a copy of the DataFrame to prevent modifying the original.\n",
    "\n",
    "    df = df.dropna().copy()  # Ensure we work on a copy\n",
    "\n",
    "# Step 3: Encode Categorical Variables\n",
    "# Identifies categorical columns (Platform, Content_Type, etc.).\n",
    "# Uses LabelEncoder() to convert categorical values into numbers.\n",
    "# Stores the encoders in a dictionary (encoders[col] = le) for later use\n",
    "\n",
    "    # Encode categorical variables\n",
    "    categorical_cols = ['Platform', 'Content_Type', 'Target_Age', 'Target_Gender', 'Region']\n",
    "    existing_categorical_cols = [col \n",
    "                                 for col in categorical_cols \n",
    "                                 if col in df.columns]\n",
    "\n",
    "    encoders = {}  # Store encoders for reuse in predictions\n",
    "    for col in existing_categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "        encoders[col] = le  # Save encoder\n",
    "        \n",
    "# Step 4: Scale Numerical Features\n",
    "#Identifies numerical columns (Budget, Duration, etc.).\n",
    "# Uses MinMaxScaler() to normalize the data between 0 and 1.\n",
    "# If no numerical columns exist, sets scaler = None.\n",
    "\n",
    "    #  Scale numerical features\n",
    "    numerical_cols = ['Budget', 'Duration', 'Clicks', 'Conversions', 'CTR', 'CPC', 'Conversion_Rate']\n",
    "    existing_numerical_cols = [col \n",
    "                               for col in numerical_cols \n",
    "                               if col in df.columns]\n",
    "\n",
    "    if existing_numerical_cols:\n",
    "        scaler = MinMaxScaler()\n",
    "        df[existing_numerical_cols] = scaler.fit_transform(df[existing_numerical_cols])\n",
    "    else:\n",
    "        scaler = None  # No scaling if no numerical columns exist\n",
    "        \n",
    "# Save encoders & scaler for reuse in predictions\n",
    "#Saves categorical encoders (label_encoders.pkl) for reuse during predictions.\n",
    "# Saves the numerical scaler (scaler.pkl) so the test data can be transformed in the same way\n",
    "    \n",
    "    with open(\"label_encoders.pkl\", \"wb\") as f:\n",
    "        pickle.dump(encoders, f)\n",
    "\n",
    "    if scaler:\n",
    "        with open(\"scaler.pkl\", \"wb\") as f:\n",
    "            pickle.dump(scaler, f)\n",
    "\n",
    "    print(\" Preprocessing completed successfully.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752cc26e-9075-4747-9f56-495a23cde7f0",
   "metadata": {},
   "source": [
    "# Execute the Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08b8a826-a1cf-4e38-9beb-4d69871ffc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      " Preprocessing completed successfully.\n",
      " Preprocessed data saved as 'cleaned_data.csv'\n"
     ]
    }
   ],
   "source": [
    "#Step 5: Execute the Script\n",
    "# Loads the dataset from SQLite.\n",
    "# Calls preprocess_data(df) to clean and transform the data.\n",
    "# Saves the cleaned dataset (cleaned_data.csv).\n",
    "# Catches and prints any errors that occur\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        df = fetch_data()\n",
    "        df_cleaned = preprocess_data(df)\n",
    "\n",
    "        if df_cleaned is not None:\n",
    "            df_cleaned.to_csv(\"cleaned_data.csv\", index=False)\n",
    "            print(\" Preprocessed data saved as 'cleaned_data.csv'\")\n",
    "        else:\n",
    "            raise ValueError(\" Preprocessing failed. No data to save.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error during preprocessing: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7bb3dc-c8ef-41aa-a907-8a49dee06459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
